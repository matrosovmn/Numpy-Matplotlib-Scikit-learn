{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1\n",
    "\n",
    "Импортируйте библиотеку Pandas и дайте ей псевдоним pd. \n",
    "Создайте датафрейм authors со столбцами author_id и author_name, в которых соответственно содержатся данные: [1, 2, 3] и ['Тургенев', 'Чехов', 'Островский'].\n",
    "Затем создайте датафрейм book cо столбцами author_id, book_title и price, в которых соответственно содержатся данные:  \n",
    "[1, 1, 1, 2, 2, 3, 3], \n",
    "['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
    "[450, 300, 350, 500, 450, 370, 290].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [author_id, author_name]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Создадим датафрейм authors со столбцами author_id и author_name\n",
    "authors = pd.DataFrame(columns=['author_id', 'author_name'])\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "Тургенев    1\n",
      "Чехов       2\n",
      "Островский  3\n"
     ]
    }
   ],
   "source": [
    "# Создадим датафрейм authors и наполним данными\n",
    "authors = pd.DataFrame([1, 2, 3], ['Тургенев', 'Чехов', 'Островский'])\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name\n",
      "0          1    Тургенев\n",
      "1          2       Чехов\n",
      "2          3  Островский\n"
     ]
    }
   ],
   "source": [
    "# Создадим датафрейм authors (запишем коротко)\n",
    "authors = pd.DataFrame({'author_id' : [1, 2, 3],\n",
    "                        'author_name' : ['Тургенев', 'Чехов', 'Островский']},\n",
    "                        columns = ['author_id','author_name'])\n",
    "print(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id            book_title  price\n",
      "0          1           Отцы и дети    450\n",
      "1          1                 Рудин    300\n",
      "2          1     Дворянское гнездо    350\n",
      "3          2      Толстый и тонкий    500\n",
      "4          2       Дама с собачкой    450\n",
      "5          3                 Гроза    370\n",
      "6          3  Таланты и поклонники    290\n"
     ]
    }
   ],
   "source": [
    "# Создадим датафрейм book\n",
    "book = pd.DataFrame({'author_id' : [1, 1, 1, 2, 2, 3, 3],\n",
    "                        'book_title' : ['Отцы и дети', 'Рудин', 'Дворянское гнездо', 'Толстый и тонкий', 'Дама с собачкой', 'Гроза', 'Таланты и поклонники'],\n",
    "                        'price' : [450, 300, 350, 500, 450, 370, 290]},\n",
    "                        columns = ['author_id','book_title', 'price'])\n",
    "print(book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 2\n",
    "\n",
    "Получите датафрейм authors_price, соединив датафреймы authors и books по полю author_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name            book_title  price\n",
      "0          1    Тургенев           Отцы и дети    450\n",
      "1          1    Тургенев                 Рудин    300\n",
      "2          1    Тургенев     Дворянское гнездо    350\n",
      "3          2       Чехов      Толстый и тонкий    500\n",
      "4          2       Чехов       Дама с собачкой    450\n",
      "5          3  Островский                 Гроза    370\n",
      "6          3  Островский  Таланты и поклонники    290\n"
     ]
    }
   ],
   "source": [
    "# Создадим объединенный датафрейм authors_price с использование функции pd.merge и прописав условие внешнего слияния how='outer' по подобию SQl \n",
    "authors_price = pd.merge(authors, book, how='outer', on = 'author_id')\n",
    "print(authors_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 3\n",
    "\n",
    "Создайте датафрейм top5, в котором содержатся строки из authors_price с пятью самыми дорогими книгами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name         book_title  price\n",
      "3          2       Чехов   Толстый и тонкий    500\n",
      "0          1    Тургенев        Отцы и дети    450\n",
      "4          2       Чехов    Дама с собачкой    450\n",
      "5          3  Островский              Гроза    370\n",
      "2          1    Тургенев  Дворянское гнездо    350\n"
     ]
    }
   ],
   "source": [
    "# Воспользуемся ранее созданым датафреймом и отсортируем данные воспользовавшись методом .nlargest\n",
    "top5 = authors_price.nlargest(5, 'price')\n",
    "print(top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4\n",
    "\n",
    "Создайте датафрейм authors_stat на основе информации из authors_price. В датафрейме authors_stat должны быть четыре столбца:\n",
    "author_name, min_price, max_price и mean_price,\n",
    "в которых должны содержаться соответственно имя автора, минимальная, максимальная и средняя цена на книги этого автора.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             min_price  max_price  mean_price\n",
      "author_name                                  \n",
      "Островский         290        370  330.000000\n",
      "Тургенев           300        450  366.666667\n",
      "Чехов              450        500  475.000000\n"
     ]
    }
   ],
   "source": [
    "# Воспользуемся ранее созданым датафреймом, сгрупируем данные по колонке author_name воспользовавшись функцией groupby передав в неё аргументы мин, макс и т.д. по колонке price,\n",
    "# переназовем колонки воспользовавшись функцией rename\n",
    "df1 = authors_price.groupby('author_name').agg({'price': 'min'}).rename(columns={'price':'min_price'})\n",
    "df2 = authors_price.groupby('author_name').agg({'price': 'max'}).rename(columns={'price':'max_price'})\n",
    "df3 = authors_price.groupby('author_name').agg({'price': 'mean'}).rename(columns={'price':'mean_price'})\n",
    "\n",
    "# Объединим в новый датафрейм полученные ранее данные\n",
    "authors_stat=pd.concat([df1, df2, df3], axis = 1)\n",
    "print(authors_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 5\n",
    "\n",
    "Создайте новый столбец в датафрейме authors_price под названием cover, в нем будут располагаться данные о том, какая обложка у данной книги - твердая или мягкая. В этот столбец поместите данные из следующего списка: ['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   author_id author_name            book_title  price    cover\n",
      "0          1    Тургенев           Отцы и дети    450  твердая\n",
      "1          1    Тургенев                 Рудин    300   мягкая\n",
      "2          1    Тургенев     Дворянское гнездо    350   мягкая\n",
      "3          2       Чехов      Толстый и тонкий    500  твердая\n",
      "4          2       Чехов       Дама с собачкой    450  твердая\n",
      "5          3  Островский                 Гроза    370   мягкая\n",
      "6          3  Островский  Таланты и поклонники    290   мягкая\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.DataFrame({'cover' : ['твердая', 'мягкая', 'мягкая', 'твердая', 'твердая', 'мягкая', 'мягкая']}, columns = ['cover'])\n",
    "# print(df4)\n",
    "authors_price = pd.concat([authors_price, df4], axis = 1)\n",
    "print(authors_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Просмотрите документацию по функции pd.pivot_table с помощью вопросительного знака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mSignature:\u001b[0m\n",
      "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0maggfunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'AggFuncType'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmargins\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmargins_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'str'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'All'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mobserved\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msort\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'bool'\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m'DataFrame'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "Create a spreadsheet-style pivot table as a DataFrame.\n",
      "\n",
      "The levels in the pivot table will be stored in MultiIndex objects\n",
      "(hierarchical indexes) on the index and columns of the result DataFrame.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "data : DataFrame\n",
      "values : column to aggregate, optional\n",
      "index : column, Grouper, array, or list of the previous\n",
      "    If an array is passed, it must be the same length as the data. The\n",
      "    list can contain any of the other types (except list).\n",
      "    Keys to group by on the pivot table index.  If an array is passed,\n",
      "    it is being used as the same manner as column values.\n",
      "columns : column, Grouper, array, or list of the previous\n",
      "    If an array is passed, it must be the same length as the data. The\n",
      "    list can contain any of the other types (except list).\n",
      "    Keys to group by on the pivot table column.  If an array is passed,\n",
      "    it is being used as the same manner as column values.\n",
      "aggfunc : function, list of functions, dict, default numpy.mean\n",
      "    If list of functions passed, the resulting pivot table will have\n",
      "    hierarchical columns whose top level are the function names\n",
      "    (inferred from the function objects themselves)\n",
      "    If dict is passed, the key is column to aggregate and value\n",
      "    is function or list of functions.\n",
      "fill_value : scalar, default None\n",
      "    Value to replace missing values with (in the resulting pivot table,\n",
      "    after aggregation).\n",
      "margins : bool, default False\n",
      "    Add all row / columns (e.g. for subtotal / grand totals).\n",
      "dropna : bool, default True\n",
      "    Do not include columns whose entries are all NaN.\n",
      "margins_name : str, default 'All'\n",
      "    Name of the row / column that will contain the totals\n",
      "    when margins is True.\n",
      "observed : bool, default False\n",
      "    This only applies if any of the groupers are Categoricals.\n",
      "    If True: only show observed values for categorical groupers.\n",
      "    If False: show all values for categorical groupers.\n",
      "\n",
      "    .. versionchanged:: 0.25.0\n",
      "\n",
      "sort : bool, default True\n",
      "    Specifies if the result should be sorted.\n",
      "\n",
      "    .. versionadded:: 1.3.0\n",
      "\n",
      "Returns\n",
      "-------\n",
      "DataFrame\n",
      "    An Excel style pivot table.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "DataFrame.pivot : Pivot without aggregation that can handle\n",
      "    non-numeric data.\n",
      "DataFrame.melt: Unpivot a DataFrame from wide to long format,\n",
      "    optionally leaving identifiers set.\n",
      "wide_to_long : Wide panel to long format. Less flexible but more\n",
      "    user-friendly than melt.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Reference :ref:`the user guide <reshaping.pivot>` for more examples.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> df = pd.DataFrame({\"A\": [\"foo\", \"foo\", \"foo\", \"foo\", \"foo\",\n",
      "...                          \"bar\", \"bar\", \"bar\", \"bar\"],\n",
      "...                    \"B\": [\"one\", \"one\", \"one\", \"two\", \"two\",\n",
      "...                          \"one\", \"one\", \"two\", \"two\"],\n",
      "...                    \"C\": [\"small\", \"large\", \"large\", \"small\",\n",
      "...                          \"small\", \"large\", \"small\", \"small\",\n",
      "...                          \"large\"],\n",
      "...                    \"D\": [1, 2, 2, 3, 3, 4, 5, 6, 7],\n",
      "...                    \"E\": [2, 4, 5, 5, 6, 6, 8, 9, 9]})\n",
      ">>> df\n",
      "     A    B      C  D  E\n",
      "0  foo  one  small  1  2\n",
      "1  foo  one  large  2  4\n",
      "2  foo  one  large  2  5\n",
      "3  foo  two  small  3  5\n",
      "4  foo  two  small  3  6\n",
      "5  bar  one  large  4  6\n",
      "6  bar  one  small  5  8\n",
      "7  bar  two  small  6  9\n",
      "8  bar  two  large  7  9\n",
      "\n",
      "This first example aggregates values by taking the sum.\n",
      "\n",
      ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "...                     columns=['C'], aggfunc=np.sum)\n",
      ">>> table\n",
      "C        large  small\n",
      "A   B\n",
      "bar one    4.0    5.0\n",
      "    two    7.0    6.0\n",
      "foo one    4.0    1.0\n",
      "    two    NaN    6.0\n",
      "\n",
      "We can also fill missing values using the `fill_value` parameter.\n",
      "\n",
      ">>> table = pd.pivot_table(df, values='D', index=['A', 'B'],\n",
      "...                     columns=['C'], aggfunc=np.sum, fill_value=0)\n",
      ">>> table\n",
      "C        large  small\n",
      "A   B\n",
      "bar one      4      5\n",
      "    two      7      6\n",
      "foo one      4      1\n",
      "    two      0      6\n",
      "\n",
      "The next example aggregates by taking the mean across multiple columns.\n",
      "\n",
      ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      "...                     aggfunc={'D': np.mean,\n",
      "...                              'E': np.mean})\n",
      ">>> table\n",
      "                D         E\n",
      "A   C\n",
      "bar large  5.500000  7.500000\n",
      "    small  5.500000  8.500000\n",
      "foo large  2.000000  4.500000\n",
      "    small  2.333333  4.333333\n",
      "\n",
      "We can also calculate multiple types of aggregations for any given\n",
      "value column.\n",
      "\n",
      ">>> table = pd.pivot_table(df, values=['D', 'E'], index=['A', 'C'],\n",
      "...                     aggfunc={'D': np.mean,\n",
      "...                              'E': [min, max, np.mean]})\n",
      ">>> table\n",
      "                  D   E\n",
      "               mean max      mean  min\n",
      "A   C\n",
      "bar large  5.500000   9  7.500000    6\n",
      "    small  5.500000   9  8.500000    8\n",
      "foo large  2.000000   5  4.500000    4\n",
      "    small  2.333333   6  4.333333    2\n",
      "\u001b[1;31mFile:\u001b[0m      c:\\users\\matro\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\pandas\\core\\reshape\\pivot.py\n",
      "\u001b[1;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "?pd.pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого автора посчитайте суммарную стоимость книг в твердой и мягкой обложке. Используйте для этого функцию pd.pivot_table. При этом столбцы должны называться \"твердая\" и \"мягкая\", а индексами должны быть фамилии авторов. Пропущенные значения стоимостей заполните нулями, при необходимости загрузите библиотеку Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cover        мягкая  твердая\n",
      "author_name                 \n",
      "Островский      660        0\n",
      "Тургенев        650      450\n",
      "Чехов             0      950\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cost_book = pd.pivot_table(authors_price, values='price', index=['author_name'], columns=['cover'], aggfunc=np.sum, fill_value=0)\n",
    "print(cost_book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Назовите полученный датасет book_info и сохраните его в формат pickle под названием \"book_info.pkl\". Затем загрузите из этого файла датафрейм и назовите его book_info2. Удостоверьтесь, что датафреймы book_info и book_info2 идентичны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_info = cost_book\n",
    "book_info.to_pickle('book_info.pkl')\n",
    "book_info2 = pd.read_pickle('book_info.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cover        мягкая  твердая\n",
      "author_name                 \n",
      "Островский      660        0\n",
      "Тургенев        650      450\n",
      "Чехов             0      950\n"
     ]
    }
   ],
   "source": [
    "print(book_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cover        мягкая  твердая\n",
      "author_name                 \n",
      "Островский      660        0\n",
      "Тургенев        650      450\n",
      "Чехов             0      950\n"
     ]
    }
   ],
   "source": [
    "print(book_info2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7c17a7cc618fb56197f4f16ec7769024701a7d4787e505151b64df9eef390f7b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
